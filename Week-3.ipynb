{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week's homework included taking samples of data from a webpage and finding the equation of the function that creates those samples. Function had 128 unknowns and weights of unknowns were either 0 or 1.\n",
    "\n",
    "After finding the weights I expected one to concat them and split into buckets of length 8 and map those buckets to their corresponding base 10 form from base 2 form and map it to ascii value of a char. At the end, every bucket corresponded to a character and when concatted they formed a word and it is the answer of this homework.\n",
    "\n",
    "Sample generatng webpage: http://sukrubezen.com/kodluyoruz/work.php\n",
    "\n",
    "Below is the code for solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def fetcher():\n",
    "     r = requests.get(\"http://sukrubezen.com/kodluyoruz/work.php\", headers={\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36\"})\n",
    "     s = r.text\n",
    "\n",
    "     ll = list(map(int, s.split()))\n",
    "     return ll\n",
    "\n",
    "\n",
    "dd = {}\n",
    "for i in range(129):\n",
    "    dd[str(i)] = []\n",
    "\n",
    "for i in range(135):\n",
    "    print (\"fetching\", i)\n",
    "    ll = fetcher()\n",
    "\n",
    "    for i in range(129):\n",
    "        dd[str(i)].append(ll[i])\n",
    "\n",
    "df = pd.DataFrame.from_dict(dd)\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "X_columns = list(map(str, range(128)))\n",
    "lr.fit(df[X_columns], df[\"128\"])\n",
    "\n",
    "cf = list(lr.coef_)\n",
    "keep = []\n",
    "for elem in cf:\n",
    "    if elem < 0.1:\n",
    "        keep.append('0')\n",
    "    else:\n",
    "        keep.append('1')\n",
    "\n",
    "print (\"\".join(keep))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I am Sukru and this is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj PRP\n",
      "am ROOT VBP\n",
      "Sukru attr NNP\n",
      "and cc CC\n",
      "this nsubj DT\n",
      "is conj VBZ\n",
      "a det DT\n",
      "sentence attr NN\n",
      ". punct .\n"
     ]
    }
   ],
   "source": [
    "for elem in doc:\n",
    "    print (elem, elem.dep_, elem.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tut = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRP'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tut.tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "Sukru Sukru\n",
      "a sentence sentence\n"
     ]
    }
   ],
   "source": [
    "for elem in doc.noun_chunks:\n",
    "    print (elem, elem.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = list(doc.noun_chunks)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, for every token there is a root and children variable which is a speciality of trees. Every token is a node in the parse tree generated when doc method is called in spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below one can find some 3rd party resources used in the lecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/ml-decision-tree/tutorial/\n",
    "\n",
    "https://www.kaggle.com/chalkalan/random-forest-tutorial\n",
    "\n",
    "https://github.com/lmcinnes/umap\n",
    "\n",
    "https://github.com/lmcinnes/umap_paper_notebooks/blob/master/UMAP%20MNIST.ipynb\n",
    "\n",
    "https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
